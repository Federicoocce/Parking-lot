{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93282d19",
   "metadata": {
    "papermill": {
     "duration": 0.005238,
     "end_time": "2024-05-23T15:33:55.080292",
     "exception": false,
     "start_time": "2024-05-23T15:33:55.075054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86187c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:33:55.090494Z",
     "iopub.status.busy": "2024-05-23T15:33:55.090128Z",
     "iopub.status.idle": "2024-05-23T15:34:02.507889Z",
     "shell.execute_reply": "2024-05-23T15:34:02.506907Z"
    },
    "papermill": {
     "duration": 7.426005,
     "end_time": "2024-05-23T15:34:02.510618",
     "exception": false,
     "start_time": "2024-05-23T15:33:55.084613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessari\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from PIL import Image\n",
    "import re\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import save\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fe909",
   "metadata": {
    "papermill": {
     "duration": 0.004451,
     "end_time": "2024-05-23T15:34:02.528501",
     "exception": false,
     "start_time": "2024-05-23T15:34:02.524050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcee2a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:34:02.539677Z",
     "iopub.status.busy": "2024-05-23T15:34:02.538729Z",
     "iopub.status.idle": "2024-05-23T15:34:02.551926Z",
     "shell.execute_reply": "2024-05-23T15:34:02.551035Z"
    },
    "papermill": {
     "duration": 0.020753,
     "end_time": "2024-05-23T15:34:02.553878",
     "exception": false,
     "start_time": "2024-05-23T15:34:02.533125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParkingLotDataset(Dataset):\n",
    "    def __init__(self, root_img, root_msk, pairs=None, transforms=None, mask_transforms=None):\n",
    "        self.root_img = root_img\n",
    "        self.root_msk = root_msk\n",
    "        self.transforms = transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "\n",
    "        if pairs is None:\n",
    "            # Get all image files\n",
    "            self.image_paths = sorted(glob.glob(os.path.join(root_img, '*.png')))\n",
    "\n",
    "            # Get all mask files\n",
    "            self.mask_paths = sorted(glob.glob(os.path.join(root_msk, '*.png')))\n",
    "\n",
    "            # Pair image and mask files based on their filenames\n",
    "            self.pairs = []\n",
    "\n",
    "            for image_path in self.image_paths:\n",
    "                image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                \n",
    "                # Remove suffix like _1, _2, _3 using regular expressions\n",
    "                image_filename_base = re.sub(r'_[1-9]$', '', image_filename)\n",
    "                \n",
    "                mask_filename = f\"{image_filename_base}_SegmentationClass.png\"\n",
    "                mask_path = os.path.join(root_msk, mask_filename)\n",
    "                \n",
    "                if os.path.exists(mask_path):\n",
    "                    self.pairs.append((image_path, mask_path))\n",
    "\n",
    "        else:\n",
    "            self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx, threshold=0.5):\n",
    "        image_path, mask_path = self.pairs[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        image_array = np.array(image)\n",
    "        self.input_channels = image_array.shape[0]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image_array = self.transforms(image_array)\n",
    "        \n",
    "\n",
    "        mask_array = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask_array = (mask_array > threshold).astype(np.float32)\n",
    "        self.input_channels = mask_array.shape[0]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.mask_transforms:\n",
    "            mask_array = self.mask_transforms(mask_array)\n",
    "\n",
    "\n",
    "        return image_array, mask_array\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed7337",
   "metadata": {
    "papermill": {
     "duration": 0.005358,
     "end_time": "2024-05-23T15:34:02.563658",
     "exception": false,
     "start_time": "2024-05-23T15:34:02.558300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "DATASET SLPIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213346f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:34:02.574091Z",
     "iopub.status.busy": "2024-05-23T15:34:02.573771Z",
     "iopub.status.idle": "2024-05-23T15:34:02.878645Z",
     "shell.execute_reply": "2024-05-23T15:34:02.877761Z"
    },
    "papermill": {
     "duration": 0.312753,
     "end_time": "2024-05-23T15:34:02.881168",
     "exception": false,
     "start_time": "2024-05-23T15:34:02.568415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/d-organ/train_images_2'\n",
    "train_mask_path = '/kaggle/input/d-organ/train_masks'\n",
    "\n",
    "val_path = '/kaggle/input/d-organ/val_images'\n",
    "val_mask_path = '/kaggle/input/d-organ/val_masks'\n",
    "\n",
    "test_path = '/kaggle/input/d-organ/test_images'\n",
    "test_mask_path = '/kaggle/input/d-organ/test_masks'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets for each split\n",
    "train_dataset = ParkingLotDataset(train_path, train_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "val_dataset = ParkingLotDataset(val_path, val_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "test_dataset = ParkingLotDataset(test_path, test_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "\n",
    "# Now you can create data loaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fced2e8",
   "metadata": {
    "papermill": {
     "duration": 0.084043,
     "end_time": "2024-05-23T15:34:08.630878",
     "exception": false,
     "start_time": "2024-05-23T15:34:08.546835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58968220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:34:08.791486Z",
     "iopub.status.busy": "2024-05-23T15:34:08.790502Z",
     "iopub.status.idle": "2024-05-23T15:34:08.805785Z",
     "shell.execute_reply": "2024-05-23T15:34:08.804971Z"
    },
    "papermill": {
     "duration": 0.097728,
     "end_time": "2024-05-23T15:34:08.807932",
     "exception": false,
     "start_time": "2024-05-23T15:34:08.710204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmallUNet_RGB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallUNet_RGB, self).__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv3 = nn.Conv2d(384, 128, 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.dropout5 = nn.Dropout(0.2)\n",
    "        self.upconv2 = nn.Conv2d(192, 64, 3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.dropout6 = nn.Dropout(0.2)\n",
    "        self.upconv1 = nn.Conv2d(96, 32, 3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        self.dropout7 = nn.Dropout(0.2)\n",
    "        self.final_conv = nn.Conv2d(32, 1, 1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.dropout1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.maxpool(conv1)\n",
    "        conv2 = self.dropout2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.maxpool(conv2)\n",
    "        conv3 = self.dropout3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.maxpool(conv3)\n",
    "        x = self.dropout4(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        # Decoder\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        x = self.dropout5(F.relu(self.bn5(self.upconv3(x))))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = self.dropout6(F.relu(self.bn6(self.upconv2(x))))\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = self.dropout7(F.relu(self.bn7(self.upconv1(x))))\n",
    "        out = self.final_conv(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1861f2",
   "metadata": {},
   "source": [
    "Loss function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9146a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth=1e-6):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    \n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)\n",
    "    \n",
    "    return 1 - loss.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, weight_dice=0.5, weight_bce=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.weight_dice = weight_dice\n",
    "        self.weight_bce = weight_bce\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(outputs, targets)\n",
    "        dice = dice_loss(torch.sigmoid(outputs), targets)\n",
    "        return self.weight_bce * bce_loss + self.weight_dice * dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f8daa6",
   "metadata": {
    "papermill": {
     "duration": 0.081453,
     "end_time": "2024-05-23T15:34:08.968501",
     "exception": false,
     "start_time": "2024-05-23T15:34:08.887048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073e9b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:34:09.129855Z",
     "iopub.status.busy": "2024-05-23T15:34:09.129464Z",
     "iopub.status.idle": "2024-05-23T15:43:42.126952Z",
     "shell.execute_reply": "2024-05-23T15:43:42.125762Z"
    },
    "papermill": {
     "duration": 573.080554,
     "end_time": "2024-05-23T15:43:42.129283",
     "exception": false,
     "start_time": "2024-05-23T15:34:09.048729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'cf05b564865bb4bf8601ed59cbace5b02a587fa9'\n",
    "#wandb.login('cf05b564865bb4bf8601ed59cbace5b02a587fa9')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SmallUNet_RGB().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "criterion = CombinedLoss()  \n",
    "epochs = 100   #100 epochs were a lot but we used them just to look after how many epochs did we arrived in an overfitting region\n",
    "update_loss=1  #variable used to update the validation loss and save the best model for each run\n",
    "\n",
    "run = wandb.init(\n",
    "    #Set the project where this run will be logged\n",
    "    project=\"Parking_lot_zones\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    "    #entity='lorenzo_barbieri'\n",
    "    entity='occelli-2127855'\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    wandb.log({\"Train Loss\": train_loss})\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device, dtype=torch.float32)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)    \n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    if val_loss<update_loss:\n",
    "        torch.save(model.state_dict(), '/kaggle/working/best_model_1_e2_no_labeled.pth')\n",
    "        print(\"model saved\")\n",
    "        update_loss = val_loss\n",
    "    wandb.log({\"Validation Loss\": val_loss})\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143fe46",
   "metadata": {},
   "source": [
    "Metrics definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1f3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(pred, target):\n",
    "    intersection = np.logical_and(pred, target)\n",
    "    union = np.logical_or(pred, target)\n",
    "    return np.sum(intersection) / np.sum(union)\n",
    "\n",
    "def dice_coefficient(pred, target):\n",
    "    intersection = np.sum(pred * target)\n",
    "    return (2. * intersection) / (np.sum(pred) + np.sum(target))\n",
    "\n",
    "def precision_score(pred, target):\n",
    "    true_positive = np.sum(np.logical_and(pred, target))\n",
    "    predicted_positive = np.sum(pred)\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "\n",
    "def recall_score(pred, target):\n",
    "    true_positive = np.sum(np.logical_and(pred, target))\n",
    "    actual_positive = np.sum(target)\n",
    "    return true_positive / actual_positive if actual_positive > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cdd43",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78ac5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:43:42.311720Z",
     "iopub.status.busy": "2024-05-23T15:43:42.311357Z",
     "iopub.status.idle": "2024-05-23T15:43:58.831353Z",
     "shell.execute_reply": "2024-05-23T15:43:58.830155Z"
    },
    "papermill": {
     "duration": 16.614775,
     "end_time": "2024-05-23T15:43:58.833953",
     "exception": false,
     "start_time": "2024-05-23T15:43:42.219178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = '/kaggle/working/segmentation_results_e2_no_label' #directory to save the images\n",
    "os.makedirs(os.path.join(save_dir, 'input_images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, 'ground_truth'), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, 'predictions'), exist_ok=True)\n",
    "\n",
    "model = SmallUNet_RGB().to(device)\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_model_1_e2_no_labeled.pth'))\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "total_iou = 0\n",
    "total_dice = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_loader):\n",
    "        images, masks = batch[:2]\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device, dtype=torch.float32)\n",
    "        outputs = model(images)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        total += masks.numel()\n",
    "        correct += (predicted == masks).sum().item()\n",
    "        \n",
    "        # Calculate metrics and save images\n",
    "        for i in range(images.size(0)):\n",
    "            pred_np = predicted[i][0].cpu().numpy()\n",
    "            mask_np = masks[i][0].cpu().numpy()\n",
    "            \n",
    "            total_iou += iou_score(pred_np, mask_np)\n",
    "            total_dice += dice_coefficient(pred_np, mask_np)\n",
    "            total_precision += precision_score(pred_np, mask_np)\n",
    "            total_recall += recall_score(pred_np, mask_np)\n",
    "            num_samples += 1\n",
    "            \n",
    "            # Save input image\n",
    "            input_img = Image.fromarray((images[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))\n",
    "            input_img.save(os.path.join(save_dir, 'input_images', f'input_{batch_idx}_{i}.png'))\n",
    "            \n",
    "            # Save ground truth mask\n",
    "            gt_mask = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
    "            gt_mask.save(os.path.join(save_dir, 'ground_truth', f'gt_{batch_idx}_{i}.png'))\n",
    "            \n",
    "            # Save predicted mask\n",
    "            pred_mask = Image.fromarray((pred_np * 255).astype(np.uint8))\n",
    "            pred_mask.save(os.path.join(save_dir, 'predictions', f'pred_{batch_idx}_{i}.png'))\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "mean_iou = total_iou / num_samples\n",
    "mean_dice = total_dice / num_samples\n",
    "mean_precision = total_precision / num_samples\n",
    "mean_recall = total_recall / num_samples\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "print(f\"Mean Dice Coefficient: {mean_dice:.4f}\")\n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "\n",
    "\n",
    "wandb.log({\n",
    "    \"Test Accuracy\": accuracy,\n",
    "    \"Mean IoU\": mean_iou,\n",
    "    \"Mean Dice Coefficient\": mean_dice,\n",
    "    \"Mean Precision\": mean_precision,\n",
    "    \"Mean Recall\": mean_recall\n",
    "})\n",
    "\n",
    "print(f\"Images saved in {save_dir}\")\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "#We needed this last code in order to download the images from kaggle\n",
    "def zipdir(path, ziph):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file), \n",
    "                       os.path.relpath(os.path.join(root, file), \n",
    "                                       os.path.join(path, '..')))\n",
    "\n",
    "output_dir = '/kaggle/working/segmentation_results_e2_no_label'  \n",
    "zipf = zipfile.ZipFile('/kaggle/working/segmentation_results_no_label.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir(output_dir, zipf)\n",
    "zipf.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5069787,
     "sourceId": 8496340,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5070683,
     "sourceId": 8497563,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 609.510358,
   "end_time": "2024-05-23T15:44:01.725082",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-23T15:33:52.214724",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
