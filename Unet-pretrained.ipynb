{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessari\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "class ParkingLotDataset(Dataset):\n",
    "    def __init__(self, root_img, root_msk, pairs=None, transforms=None, mask_transforms=None):\n",
    "        self.root_img = root_img\n",
    "        self.root_msk = root_msk\n",
    "        self.transforms = transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "\n",
    "        if pairs is None:\n",
    "            # Get all image files\n",
    "            self.image_paths = sorted(glob.glob(os.path.join(root_img, '*.png')))\n",
    "\n",
    "            # Get all mask files\n",
    "            self.mask_paths = sorted(glob.glob(os.path.join(root_msk, '*.png')))\n",
    "\n",
    "            # Pair image and mask files based on their filenames\n",
    "            #self.pairs = [(image_path, mask_path) for image_path in self.image_paths for mask_path in self.mask_paths if os.path.splitext(os.path.basename(image_path))[0] == os.path.splitext(os.path.basename(mask_path))[0]]\n",
    "            self.pairs = []\n",
    "\n",
    "            for image_path in self.image_paths:\n",
    "                image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                mask_filename = f\"{image_filename}_SegmentationClass.png\"\n",
    "                mask_path = os.path.join(root_msk, mask_filename)\n",
    "                if os.path.exists(mask_path):\n",
    "                    self.pairs.append((image_path, mask_path))\n",
    "\n",
    "        else:\n",
    "            self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx, threshold=0.5):\n",
    "        image_path, mask_path = self.pairs[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        image_array = np.array(image)\n",
    "        self.input_channels = image_array.shape[0]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image_array = self.transforms(image_array)\n",
    "        \n",
    "        #mask = Image.open(mask_path)\n",
    "        #mask_array = np.array(mask)\n",
    "        mask_array = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask_array = (mask_array > threshold).astype(np.float32)\n",
    "        self.input_channels = mask_array.shape[0]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.mask_transforms:\n",
    "            mask_array = self.mask_transforms(mask_array)\n",
    "\n",
    "\n",
    "        return image_array, mask_array\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# magari rifare il dataloader con due cartelle\n",
    "train_path = '/kaggle/input/big-ddd/Dataset_splittato/train_images'\n",
    "train_mask_path = '/kaggle/input/big-ddd/Dataset_splittato/train_masks'\n",
    "\n",
    "val_path = '/kaggle/input/big-ddd/Dataset_splittato/val_images'\n",
    "val_mask_path = '/kaggle/input/big-ddd/Dataset_splittato/val_masks'\n",
    "\n",
    "test_path = '/kaggle/input/big-ddd/Dataset_splittato/test_images'\n",
    "test_mask_path = '/kaggle/input/big-ddd/Dataset_splittato/test_masks'\n",
    "\n",
    "#normalize = transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "#normalize = transforms.Normalize(mean=[35.5, 35.2, 33.4], std=[21.8, 21.6, 20.9])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    #transforms.Normalize(mean=[35.5, 35.2, 33.4], std=[21.8, 21.6, 20.9]),\n",
    "    # Add other transforms here as needed\n",
    "])\n",
    "\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    # Add other mask transformations here\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Create datasets for each split\n",
    "train_dataset = ParkingLotDataset(train_path, train_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "val_dataset = ParkingLotDataset(val_path, val_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "test_dataset = ParkingLotDataset(test_path, test_mask_path, transforms=transform, mask_transforms=mask_transforms)\n",
    "\n",
    "# Now you can create data loaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import save\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import segmentation_models_pytorch as smp\n",
    "wandb.login(key='cf05b564865bb4bf8601ed59cbace5b02a587fa9')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the pretrained U-Net model\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",  # Choose the encoder (backbone)\n",
    "    encoder_weights=\"imagenet\",  # Use pre-trained weights from ImageNet\n",
    "    in_channels=3,  # Input channels (RGB)\n",
    "    classes=1,  # Binary segmentation\n",
    ")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 10\n",
    "run = wandb.init(\n",
    "    #Set the project where this run will be logged\n",
    "    project=\"Parking_lot_zones\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": epochs,\n",
    "    },\n",
    "    #entity='lorenzo_barbieri'\n",
    "    entity='occelli-2127855'\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    wandb.log({\"Train Loss\": train_loss})\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device, dtype=torch.float32)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    wandb.log({\"Validation Loss\": val_loss})\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Testing loop\n",
    "total = 0\n",
    "correct = 0\n",
    "batch_idx = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images, masks = batch[:2]  # Unpack the first two values (images and masks)\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device, dtype=torch.float32)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Threshold the outputs to obtain binary masks\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        # Compute the accuracy\n",
    "        total += masks.numel()  # Total number of elements in the batch\n",
    "        correct += (predicted == masks).sum().item()  # Correctly predicted elements\n",
    "\n",
    "        # Plot the first 5 outputs\n",
    "        if batch_idx < 14:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(images[0].permute(1, 2, 0).cpu().numpy())\n",
    "            plt.title('Input Image')\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(masks[0][0].cpu(), cmap='gray')\n",
    "            plt.title('Ground Truth Mask')\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted[0][0].cpu(), cmap='gray')\n",
    "            plt.title('Predicted Mask')\n",
    "            plt.show()\n",
    "        batch_idx += 1\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")\n",
    "wandb.log({\"Test Accuracy\": accuracy})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
