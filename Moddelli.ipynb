{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessari\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controllo il massimo valore di altezza e larghezza per fare il padding\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing the images\n",
    "data_dir = 'Resizedmasks'\n",
    "\n",
    "# Initialize variables to store max height and width\n",
    "max_height = 0\n",
    "max_width = 0\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Get height and width of the image\n",
    "        height, width, _ = image.shape\n",
    "        if(height != 1000 or width != 1000):\n",
    "            print(filename)\n",
    "            print(image.shape)\n",
    "\n",
    "        # Update max_height and max_width if necessary\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "\n",
    "        \n",
    "\n",
    "#Image with different max_height and max_width: Queretaro-TEC_parcheggi.png\n",
    "print(\"Maximum Height:\", max_height)\n",
    "print(\"Maximum Width:\", max_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing the images\n",
    "data_dir = 'Dataset'\n",
    "# Directory to save resized images\n",
    "resized_dir = 'ResizedDataset'\n",
    "\n",
    "# Ensure the resized_dir exists\n",
    "os.makedirs(resized_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Get height and width of the image\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # If the image is larger than 1000 in either dimension, resize it\n",
    "        if height > 1000 or width > 1000:\n",
    "            # Calculate the scale factor\n",
    "            scale_factor = 0.5  # Reduce size by half\n",
    "\n",
    "            # Calculate the new dimensions of the image\n",
    "            new_width = int(width * scale_factor)\n",
    "            new_height = int(height * scale_factor)\n",
    "\n",
    "            # Resize the image\n",
    "            image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "        # Save the image (resized or original) to the new directory\n",
    "        new_image_path = os.path.join(resized_dir, filename)\n",
    "        cv2.imwrite(new_image_path, image)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask resize and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing the images\n",
    "data_dir = 'image_newmask'\n",
    "# Directory to save resized images\n",
    "resized_dir = 'Resizedmasks'\n",
    "\n",
    "# Ensure the resized_dir exists\n",
    "os.makedirs(resized_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Get height and width of the image\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # If the image is larger than 1000 in either dimension, resize it\n",
    "        if height > 1000 or width > 1000:\n",
    "            # Calculate the scale factor\n",
    "            scale_factor = 0.5  # Reduce size by half\n",
    "\n",
    "            # Calculate the new dimensions of the image\n",
    "            new_width = int(width * scale_factor)\n",
    "            new_height = int(height * scale_factor)\n",
    "\n",
    "            # Resize the image\n",
    "            image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "        ## MASK PADDING\n",
    "        max_height = 1056\n",
    "        max_width = 1056\n",
    "        padding_height = max(0, max_height - image.shape[0])\n",
    "        padding_width = max(0, max_width - image.shape[1])\n",
    "        mask_padded = cv2.copyMakeBorder(image, 0, padding_height, 0, padding_width, cv2.BORDER_CONSTANT, value=0)\n",
    "        # Save the image (resized or original) to the new directory\n",
    "        new_image_path = os.path.join(resized_dir, filename)\n",
    "        cv2.imwrite(new_image_path, mask_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('Dataset_edge'):\n",
    "    image_path = os.path.join('Dataset_edge', filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image.shape[0] != 1056 or image.shape[1] != 1056:\n",
    "        print(image_path)\n",
    "        print(image.shape[0],image.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store canny edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'ResizedDataset'\n",
    "edge_path = 'Dataset_edge'\n",
    "\n",
    "os.makedirs(edge_path, exist_ok=True)\n",
    "\n",
    "def get_edge_image(image, low_threshold, high_threshold):\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    \n",
    "    return edges\n",
    "#edge detection + padding immagini\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        \n",
    "        input_image_path = os.path.join(dataset_path, filename)\n",
    "        image = cv2.imread(input_image_path)\n",
    "        # Ottieni l'immagine del bordo\n",
    "        edge_image = get_edge_image(image, low_threshold=200, high_threshold=300)\n",
    "        \n",
    "        # Apply padding to the edge image\n",
    "        max_height = 1056\n",
    "        max_width = 1056\n",
    "        padding_height = max(0, max_height - edge_image.shape[0])\n",
    "        padding_width = max(0, max_width - edge_image.shape[1])\n",
    "        edge_image_padded = cv2.copyMakeBorder(edge_image, 0, padding_height, 0, padding_width, cv2.BORDER_CONSTANT, value=0)\n",
    "        #Verificare se il nome del file contiene \"_testing\" o \"_training\"\n",
    "        if \"_testing\" in filename or \"_training\" in filename:\n",
    "            # Rinominare il file rimuovendo \"_testing\" o \"_training\" dal nome\n",
    "            new_filename = filename.replace(\"_testing\", \"\").replace(\"_training\", \"\")\n",
    "            \n",
    "            print(f\"Rinominato il file {filename} in {new_filename}\")\n",
    "            # Salva l'immagine del bordo nella cartella di output\n",
    "            output_image_path = os.path.join(edge_path, new_filename)\n",
    "            cv2.imwrite(output_image_path, edge_image_padded)\n",
    "\n",
    "print(\"Il rilevamento dei bordi Ã¨ stato applicato a tutte le immagini nella cartella.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the paths to the mask and image folders\n",
    "mask_folder = 'Dataset_mask'\n",
    "image_folder = 'Dataset_edge'\n",
    "\n",
    "# Create a new folder to store the combined images and masks\n",
    "combined_folder = 'Dataset_combined'\n",
    "os.makedirs(combined_folder, exist_ok=True)\n",
    "\n",
    "# Copy all files from the mask folder to the combined folder\n",
    "for mask_file in os.listdir(mask_folder):\n",
    "    shutil.copy2(os.path.join(mask_folder, mask_file), combined_folder)\n",
    "\n",
    "# Copy all files from the image folder to the combined folder\n",
    "for image_file in os.listdir(image_folder):\n",
    "    shutil.copy2(os.path.join(image_folder, image_file), combined_folder)\n",
    "\n",
    "print(\"Masks and images have been combined and stored in the 'Combined' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "class ParkingLotDataset(Dataset):\n",
    "    def __init__(self, root_img, root_msk, pairs=None, transforms=None):\n",
    "        self.root_img = root_img\n",
    "        self.root_msk = root_msk\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if pairs is None:\n",
    "            # Get all image files\n",
    "            self.image_paths = sorted(glob.glob(os.path.join(root_img, '*.png')))\n",
    "\n",
    "            # Get all mask files\n",
    "            self.mask_paths = sorted(glob.glob(os.path.join(root_msk, '*.png')))\n",
    "\n",
    "            # Pair image and mask files based on their filenames\n",
    "            #self.pairs = [(image_path, mask_path) for image_path in self.image_paths for mask_path in self.mask_paths if os.path.splitext(os.path.basename(image_path))[0] == os.path.splitext(os.path.basename(mask_path))[0]]\n",
    "            self.pairs = []\n",
    "\n",
    "            for image_path in self.image_paths:\n",
    "                image_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                mask_filename = f\"{image_filename}_SegmentationClass.png\"\n",
    "                mask_path = os.path.join(root_msk, mask_filename)\n",
    "                if os.path.exists(mask_path):\n",
    "                    self.pairs.append((image_path, mask_path))\n",
    "\n",
    "        else:\n",
    "            self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, mask_path = self.pairs[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image_array = self.transforms(image_array)\n",
    "            \n",
    "        \n",
    "        #mask = Image.open(mask_path)\n",
    "        #mask_array = np.array(mask)\n",
    "        mask_array = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            mask_array = self.transforms(mask_array)\n",
    "            \n",
    "\n",
    "\n",
    "        return image_array, mask_array\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET SLPIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# magari rifare il dataloader con due cartelle\n",
    "image_path = '/kaggle/input/dataset-conedge/Dataset_edge'\n",
    "mask_path = '/kaggle/input/dataset-conedge/Resizedmasks'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    # Add other transforms here as needed\n",
    "])\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ParkingLotDataset(image_path, mask_path, transforms=transform)\n",
    "\n",
    "# Define the proportions for the split\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "total_size = len(dataset)\n",
    "print(total_size)\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(dataset.pairs)\n",
    "\n",
    "# Calculate the sizes of each split\n",
    "total_size = len(dataset)\n",
    "print(total_size)\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_pairs = dataset.pairs[:train_size]\n",
    "val_pairs = dataset.pairs[train_size:train_size+val_size]\n",
    "test_pairs = dataset.pairs[train_size+val_size:]\n",
    "\n",
    "# Create datasets for each split\n",
    "train_dataset = ParkingLotDataset(image_path, mask_path, pairs=train_pairs, transforms=transform)\n",
    "val_dataset = ParkingLotDataset(image_path, mask_path, pairs=val_pairs, transforms=transform)\n",
    "test_dataset = ParkingLotDataset(image_path, mask_path, pairs=test_pairs, transforms=transform )\n",
    "\n",
    "# Now you can create data loaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataLoader object called train_loader\n",
    "num_samples = 10\n",
    "\n",
    "# Iterate over batches from the DataLoader\n",
    "for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "    # Get the number of samples in the current batch\n",
    "    batch_size = images.size(0)\n",
    "\n",
    "    # Iterate over the samples in the batch\n",
    "    for i in range(batch_size):\n",
    "        # Convert the image tensor to a NumPy array\n",
    "        image_array = images[i].permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Convert the mask tensor to a NumPy array\n",
    "        mask_array = masks[i].permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Plot the image and the combined mask\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_array, cmap='gray')\n",
    "        plt.title(f'Image {batch_idx * batch_size + i + 1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image_array, cmap='gray')\n",
    "        plt.imshow(mask_array, cmap='gray', alpha=0.5)\n",
    "        plt.title(f'Image {batch_idx * batch_size + i + 1} with Masks')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Break after the first 10 samples\n",
    "        if batch_idx * batch_size + i == num_samples - 1:\n",
    "            break\n",
    "\n",
    "    # Break after processing one batch\n",
    "    if batch_idx == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "class SmallUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallUNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.Conv2d(128, 32, 3, padding=1)\n",
    "        self.upconv1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = F.relu(self.conv1(x))\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "        x = F.relu(self.upconv2(x))\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "        x = F.relu(self.upconv1(x))\n",
    "\n",
    "        out = torch.sigmoid(self.final_conv(x))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "# Start a new run\n",
    "#run = wandb.init(project='Parking_lot_zones', entity='Fede_occe')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SmallUNet().to(device)\n",
    "optimizer = optim.sgd(model.parameters(), lr=0.01)\n",
    "#wandb.watch(model)\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #wandb.log({\"Train Loss\": loss.item()})\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            val_loss = F.binary_cross_entropy_with_logits(outputs, masks)\n",
    "\n",
    "            #wandb.log({\"Validation Loss\": val_loss.item()})\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
