{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessari\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edge_image(image, low_threshold, high_threshold):\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread(r'C:\\Users\\loren\\Downloads\\APKLOT-master\\APKLOT-master\\1. Satellite\\Dataset\\parcheggi\\Dataset\\402492112_training.png')\n",
    "\n",
    "# Get the edge image\n",
    "edge_image = get_edge_image(image, low_threshold=250, high_threshold=350)\n",
    "\n",
    "# Display the edge image\n",
    "cv2.imshow('Edge Image', edge_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store canny edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r'C:\\Users\\loren\\Downloads\\APKLOT-master\\APKLOT-master\\1. Satellite\\Dataset\\parcheggi\\Dataset'\n",
    "edge_path = r'C:\\Users\\loren\\Downloads\\APKLOT-master\\APKLOT-master\\1. Satellite\\Dataset\\parcheggi\\Dataset_edge'\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        input_image_path = os.path.join(dataset_path, filename)\n",
    "        image = cv2.imread(input_image_path)\n",
    "        # Ottieni l'immagine del bordo\n",
    "        edge_image = get_edge_image(image, low_threshold=250, high_threshold=350)\n",
    "        # Salva l'immagine del bordo nella cartella di output\n",
    "        output_image_path = os.path.join(edge_path, filename)\n",
    "        cv2.imwrite(output_image_path, edge_image)\n",
    "\n",
    "print(\"Il rilevamento dei bordi Ã¨ stato applicato a tutte le immagini nella cartella.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Height: 2108\n",
      "Maximum Width: 2113\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'padding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 67\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum Width:\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_width)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Data transformations\u001b[39;00m\n\u001b[0;32m     65\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     66\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((max_height, max_width)),  \u001b[38;5;66;03m# Resize to maximum dimensions\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mPad(\u001b[43mpadding\u001b[49m),  \u001b[38;5;66;03m# Pad images to make them all the same size\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[0;32m     69\u001b[0m ])\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Combine image and mask paths\u001b[39;00m\n\u001b[0;32m     72\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'padding' is not defined"
     ]
    }
   ],
   "source": [
    "# Custom dataset class\n",
    "class ParkingLotDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        #image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Load masks\n",
    "        with open(mask_path, 'r') as f:\n",
    "            masks_data = json.load(f)\n",
    "\n",
    "        masks = []\n",
    "        for shape in masks_data['shapes']:\n",
    "            points = np.array(shape['points'])\n",
    "            mask = np.zeros_like(image[:, :, 0])\n",
    "            cv2.fillPoly(mask, [points.astype(np.int32)], 1)\n",
    "            masks.append(mask)\n",
    "\n",
    "        masks = np.stack(masks, axis=0).astype(np.float32)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            masks = self.transforms(masks)\n",
    "\n",
    "        return image, masks\n",
    "\n",
    "# Initialize variables to store max height and width\n",
    "max_height = 0\n",
    "max_width = 0\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir('C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader'):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join('C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader', filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Get height and width of the image\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # Update max_height and max_width if necessary\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "\n",
    "print(\"Maximum Height:\", max_height)\n",
    "print(\"Maximum Width:\", max_width)\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((max_height, max_width)),  # Resize to maximum dimensions\n",
    "    transforms.Pad(padding),  # Pad images to make them all the same size\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Combine image and mask paths\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "for filename in os.listdir('C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader'):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = 'C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader'+ '/' + filename\n",
    "        mask_path = 'C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader'+ '/' + filename.replace('.png', '.json')\n",
    "        image_paths.append(image_path)\n",
    "        mask_paths.append(mask_path)\n",
    "\n",
    "# Create dataset\n",
    "dataset = ParkingLotDataset(image_paths, mask_paths, transforms=transform)\n",
    "\n",
    "# Split image and mask paths into train and test sets\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(dataset.image_paths, dataset.mask_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train set into train and validation sets\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define datasets and data loaders for train, validation, and test sets\n",
    "train_dataset = ParkingLotDataset(train_images, train_masks, transforms=transform)\n",
    "val_dataset = ParkingLotDataset(val_images, val_masks, transforms=transform)\n",
    "test_dataset = ParkingLotDataset(test_images, test_masks, transforms=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display images and masks from the train data loader\n",
    "for images, masks in train_data_loader:\n",
    "    for i in range(images.size(0)):\n",
    "        image = images[i].permute(1, 2, 0).numpy()\n",
    "        mask = masks[i].permute(1, 2, 0).numpy()\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title('Image')\n",
    "        ax2.imshow(mask.squeeze(), cmap='gray')\n",
    "        ax2.set_title('Mask')\n",
    "        plt.show()\n",
    "        break  # Display only one batch\n",
    "    break  # Display only one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Height: 2108\n",
      "Maximum Width: 2113\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing the images\n",
    "data_dir = 'C:/Users/loren/Downloads/APKLOT-master/APKLOT-master/1. Satellite/Dataset/parcheggi/dataloader'\n",
    "\n",
    "# Initialize variables to store max height and width\n",
    "max_height = 0\n",
    "max_width = 0\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(data_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Get height and width of the image\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        # Update max_height and max_width if necessary\n",
    "        if height > max_height:\n",
    "            max_height = height\n",
    "        if width > max_width:\n",
    "            max_width = width\n",
    "\n",
    "print(\"Maximum Height:\", max_height)\n",
    "print(\"Maximum Width:\", max_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained Mask R-CNN model\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Set the number of classes (in this case, 1 for parking lot regions)\n",
    "num_classes = 2  # Background and parking lot region\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace the pre-trained classifier with a new one\n",
    "model.roi_heads.box_predictor = maskrcnn_resnet50_fpn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Move the model to the desired device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "maskcriterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
